{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CT-Seg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXuouw4BbfyLJ/tqTW9Cck",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takhtardeshirsoheib/soheib/blob/master/CT_Seg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEQGOH8S8yOn"
      },
      "source": [
        "\n",
        "class Config:\n",
        "    \n",
        "    def __init__(self):\n",
        "        #network configure\n",
        "        self.InputCh=3\n",
        "        self.ScaleRatio = 2\n",
        "        self.ConvSize = 3\n",
        "        self.pad = 1#(self.ConvSize - 1) / 2 \n",
        "        self.MaxLv = 5\n",
        "        self.ChNum = [self.InputCh,64]\n",
        "        for i in range(self.MaxLv-1):\n",
        "            self.ChNum.append(self.ChNum[-1]*2)\n",
        "        #data configure\n",
        "        self.pascal = \"/content/drive/My Drive/CT/CT1/\"\n",
        "        self.bsds = \"../BSR/BSDS500/data/images/\"\n",
        "        #self.imagelist = \"ImageSets/Segmentation/train.txt\"\n",
        "        self.BatchSize = 6\n",
        "        self.Shuffle = True\n",
        "        self.LoadThread = 4\n",
        "        self.inputsize = [224,224]\n",
        "        #partition configure\n",
        "        self.K = 64\n",
        "        #training configure\n",
        "        self.init_lr = 0.05\n",
        "        self.lr_decay = 0.1\n",
        "        self.lr_decay_iter = 1000\n",
        "        self.max_iter = 50000\n",
        "        self.cuda_dev = 0 \n",
        "        self.cuda_dev_list = \"0,1\"\n",
        "        self.check_iter = 1000\n",
        "        #Ncuts Loss configure\n",
        "        self.radius = 4\n",
        "        self.sigmaI = 10\n",
        "        self.sigmaX = 4\n",
        "        #testing configure\n",
        "        self.model_tested = \"./checkpoint_8_23_13_0_epoch_2000\"\n",
        "        #color library\n",
        "        self.color_lib = []\n",
        "        for r in range(0,256,128):\n",
        "            for g in range(0,256,128):\n",
        "                for b in range(0,256,128):\n",
        "                    self.color_lib.append((r,g,b))\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKR3-PFO9i8c",
        "outputId": "dc3b2089-b980-4da2-ca7d-90cb21b6d88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NosKgJP2-TUY"
      },
      "source": [
        "from PIL import Image\n",
        "import PIL\n",
        "import torch\n",
        "import torch.utils.data as Data\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pdb\n",
        "import math\n",
        "import cupy as cp\n",
        "PIL.ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "config = Config()\n",
        "\n",
        "class DataLoader():\n",
        "    #initialization\n",
        "    #datapath : the data folder of bsds500\n",
        "    #mode : train/test/val\n",
        "    def __init__(self, datapath,mode):\n",
        "        #image container\n",
        "        self.path = \"/content/drive/My Drive/CT/CT1/\"\n",
        "        self.Imgpath = os.listdir(self.path)\n",
        "        self.raw_data = []\n",
        "        self.mode = mode\n",
        "        print(self.Imgpath)\n",
        "        #navigate to the image directory\n",
        "        #images_path = os.path.join(datapath,'images')\n",
        "        train_image_path = os.path.join(datapath,mode)\n",
        "        file_list = []\n",
        "        if(mode != \"train\"):\n",
        "            train_image_regex = os.path.join(train_image_path, '*.jpg')\n",
        "            file_list = glob.glob(train_image_regex)\n",
        "        #find all the images\n",
        "        else:\n",
        "            for i in range (len(self.Imgpath)):\n",
        "              file_list.append(self.path + self.Imgpath[i])    \n",
        "        #load the images\n",
        "        for file_name in file_list:\n",
        "            image = Image.open(file_name)\n",
        "            if image.mode != \"RGB\":\n",
        "              image = image.convert(\"RGB\")\n",
        "            self.raw_data.append(np.array(image.resize((config.inputsize[0],config.inputsize[1]),Image.BILINEAR)))\n",
        "        #resize and align\n",
        "        self.scale()\n",
        "        #normalize\n",
        "        self.transfer()\n",
        "        \n",
        "        #calculate weights by 2\n",
        "        if(mode == \"train\"):\n",
        "            self.dataset = self.get_dataset(self.raw_data, self.raw_data.shape,75)\n",
        "        else:\n",
        "            self.dataset = self.get_dataset(self.raw_data, self.raw_data.shape,75)\n",
        "    \n",
        "    def scale(self):\n",
        "        for i in range(len(self.raw_data)):\n",
        "            image = self.raw_data[i]\n",
        "            self.raw_data[i] = np.stack((image[:,:,0],image[:,:,1],image[:,:,2]),axis = 0)\n",
        "        self.raw_data = np.stack(self.raw_data,axis = 0)\n",
        "\n",
        "    def transfer(self):\n",
        "        #just for RGB 8-bit color\n",
        "        self.raw_data = self.raw_data.astype(np.float)\n",
        "        #for i in range(self.raw_data.shape[0]):\n",
        "        #    Image.fromarray(self.raw_data[i].swapaxes(0,-1).astype(np.uint8)).save(\"./reconstruction/input_\"+str(i)+\".jpg\")\n",
        "\n",
        "    def torch_loader(self):\n",
        "        return Data.DataLoader(\n",
        "                                self.dataset,\n",
        "                                batch_size = config.BatchSize,\n",
        "                                shuffle = config.Shuffle,\n",
        "                                num_workers = config.LoadThread,\n",
        "                                pin_memory = True,\n",
        "                            )\n",
        "\n",
        "    def cal_weight(self,raw_data,shape):\n",
        "        #According to the weight formula, when Euclidean distance < r,the weight is 0, so reduce the dissim matrix size to radius-1 to save time and space.\n",
        "        print(\"calculating weights.\")\n",
        "\n",
        "        dissim = cp.zeros((shape[0],shape[1],shape[2],shape[3],(config.radius-1)*2+1,(config.radius-1)*2+1))\n",
        "        data = cp.asarray(raw_data)\n",
        "        padded_data = cp.pad(data,((0,0),(0,0),(config.radius-1,config.radius-1),(config.radius-1,config.radius-1)),'constant')\n",
        "        for m in range(2*(config.radius-1)+1):\n",
        "            for n in range(2*(config.radius-1)+1):\n",
        "                dissim[:,:,:,:,m,n] = data-padded_data[:,:,m:shape[2]+m,n:shape[3]+n]\n",
        "        #for i in range(dissim.shape[0]):\n",
        "        #dissim = -cp.power(dissim,2).sum(1,keepdims = True)/config.sigmaI/config.sigmaI\n",
        "        temp_dissim = cp.exp(-cp.power(dissim,2).sum(1,keepdims = True)/config.sigmaI**2)\n",
        "        dist = cp.zeros((2*(config.radius-1)+1,2*(config.radius-1)+1))\n",
        "        for m in range(1-config.radius,config.radius):\n",
        "            for n in range(1-config.radius,config.radius):\n",
        "                if m**2+n**2<config.radius**2:\n",
        "                    dist[m+config.radius-1,n+config.radius-1] = cp.exp(-(m**2+n**2)/config.sigmaX**2)\n",
        "        #for m in range(0,config.radius-1):\n",
        "        #    temp_dissim[:,:,m,:,0:config.radius-1-m,:]=0.0\n",
        "        #    temp_dissim[:,:,-1-m,:,m-config.radius+1:-1,:]=0.0\n",
        "        #    temp_dissim[:,:,:,m,:,0:config.radius-1-m]=0.0\n",
        "        #    temp_dissim[:,:,:,-1-m,:,m-config.radius+1:-1]=0.0\n",
        "        print(\"weight calculated.\")\n",
        "        res = cp.multiply(temp_dissim,dist)\n",
        "        #for m in range(50,70):\n",
        "\n",
        "        #    print(m)\n",
        "        #    for n in range(50,70):\n",
        "        #        print(dissim[5,0,m,n])\n",
        "        #print(dist)\n",
        "        return res\n",
        "\n",
        "    def get_dataset(self,raw_data,shape,batch_size):\n",
        "        dataset = []\n",
        "        for batch_id in range(0,shape[0],batch_size):\n",
        "            print(batch_id)\n",
        "            batch = raw_data[batch_id:min(shape[0],batch_id+batch_size)]\n",
        "            if(self.mode == \"train\"):\n",
        "                tmp_weight = self.cal_weight(batch,batch.shape)\n",
        "                weight = cp.asnumpy(tmp_weight)\n",
        "                dataset.append(Data.TensorDataset(torch.from_numpy(batch/256).float(),torch.from_numpy(weight).float()))\n",
        "                del tmp_weight\n",
        "            else:\n",
        "                dataset.append(Data.TensorDataset(torch.from_numpy(batch/256).float()))\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "        return Data.ConcatDataset(dataset)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHkQaqoQ-c3J"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functional\n",
        "import pdb\n",
        "config = Config()\n",
        "\n",
        "class WNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WNet, self).__init__()\n",
        "        self.feature1 = []\n",
        "        self.feature2 = []\n",
        "        bias = True\n",
        "        #U-Net1\n",
        "        #module1\n",
        "        self.module = []\n",
        "        self.maxpool1 = []\n",
        "        self.uconv1 = []\n",
        "        self.module.append(\n",
        "            self.add_conv_stage(config.ChNum[0],config.ChNum[1],config.ConvSize,padding=config.pad,seperable=False)   \n",
        "        )\n",
        "        \n",
        "        #module2-5\n",
        "        for i in range(2,config.MaxLv+1):\n",
        "            self.module.append(self.add_conv_stage(config.ChNum[i-1],config.ChNum[i],config.ConvSize,padding=config.pad))\n",
        "            \n",
        "        #module6-8\n",
        "        for i in range(config.MaxLv-1,1,-1):\n",
        "            self.module.append(self.add_conv_stage(2*config.ChNum[i],config.ChNum[i],config.ConvSize,padding=config.pad))\n",
        "        #module9\n",
        "        self.module.append(\n",
        "            self.add_conv_stage(2*config.ChNum[1],config.ChNum[1],config.ConvSize,padding=config.pad,seperable=False)\n",
        "        )\n",
        "        #module1-4\n",
        "        for i in range(config.MaxLv-1):\n",
        "            self.maxpool1.append(nn.MaxPool2d(config.ScaleRatio))\n",
        "        #module5-8\n",
        "        for i in range(config.MaxLv,1,-1):\n",
        "            self.uconv1.append(nn.ConvTranspose2d(config.ChNum[i],config.ChNum[i-1],config.ScaleRatio,config.ScaleRatio,bias = True))\n",
        "        self.predconv = nn.Conv2d(config.ChNum[1],config.K,1,bias = bias)\n",
        "        self.pad = nn.ConstantPad2d(config.radius-1,0)\n",
        "        self.softmax = nn.Softmax2d()\n",
        "        self.module = torch.nn.ModuleList(self.module)\n",
        "        self.maxpool1 = torch.nn.ModuleList(self.maxpool1)\n",
        "        self.uconv1 = torch.nn.ModuleList(self.uconv1)\n",
        "        #self.loss = NcutsLoss()\n",
        "    def add_conv_stage(self,dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=True, seperable=True):\n",
        "        if seperable:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(dim_in,dim_out,1,bias = bias),\n",
        "                nn.Conv2d(dim_out,dim_out,kernel_size,padding = padding,groups = dim_out,bias = bias),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(dim_out),\n",
        "                nn.Conv2d(dim_out,dim_out,1,bias = bias),\n",
        "                nn.Conv2d(dim_out,dim_out,kernel_size,padding = padding,groups = dim_out,bias = bias),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(dim_out),\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(dim_in,dim_out,kernel_size,padding = padding,bias = bias),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(dim_out),\n",
        "                nn.Conv2d(dim_out,dim_out,kernel_size,padding = padding,bias = bias),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(dim_out),\n",
        "            )\n",
        "    def forward(self,x):\n",
        "        self.feature1 = [x]\n",
        "        #U-Net1\n",
        "        self.feature1.append(self.module[0](x))\n",
        "        for i in range(1,config.MaxLv):\n",
        "            tempf = self.maxpool1[i-1](self.feature1[-1])\n",
        "            self.feature1.append(self.module[i](tempf))\n",
        "        for i in range(config.MaxLv,2*config.MaxLv-2):\n",
        "            tempf = self.uconv1[i-config.MaxLv](self.feature1[-1])\n",
        "            tempf = torch.cat((self.feature1[2*config.MaxLv-i-1],tempf),dim=1)\n",
        "            self.feature1.append(self.module[i](tempf))\n",
        "        tempf = self.uconv1[-1](self.feature1[-1])\n",
        "        tempf = torch.cat((self.feature1[1],tempf),dim=1)\n",
        "        tempf = self.module[-1](tempf)\n",
        "        tempf = self.predconv(tempf)\n",
        "        self.feature2 = [self.softmax(tempf)]\n",
        "        return [self.feature2[0],self.pad(self.feature2[0])]\n",
        "        #self.feature2.append(self.loss(self.feature2[0],self.feature2[1],w,sw))\n",
        "        #U-Net2\n",
        "        \n",
        "        '''tempf = self.conv2[0](self.feature2[-1])\n",
        "        tempf = self.ReLU2[0](tempf)\n",
        "        tempf = self.bn2[0](tempf)\n",
        "        tempf = self.conv2[1](tempf)\n",
        "        tempf = self.ReLU2[1](tempf)\n",
        "        self.feature2.append(self.bn2[1](tempf))\n",
        "\n",
        "        for i in range(1,config.MaxLv):\n",
        "            tempf = self.maxpool2[i-1](self.feature2[-1])\n",
        "            tempf = self.conv2[4*i-2](tempf)\n",
        "            tempf = self.conv2[4*i-1](tempf)\n",
        "            tempf = self.ReLU2[2*i](tempf)\n",
        "            tempf = self.bn2[2*i](tempf)\n",
        "            tempf = self.conv2[4*i](tempf)\n",
        "            tempf = self.conv2[4*i+1](tempf)\n",
        "            tempf = self.ReLU2[2*i+1](tempf)\n",
        "            \n",
        "            self.feature2.append(self.bn2[2*i+1](tempf))\n",
        "        for i in range(config.MaxLv,2*config.MaxLv-2):\n",
        "            tempf = self.uconv2[i-config.MaxLv](self.feature2[-1])\n",
        "            tempf = torch.cat((self.feature2[2*config.MaxLv-i-1],tempf),dim=1)\n",
        "            tempf = self.conv2[4*i-2](tempf)\n",
        "            tempf = self.conv2[4*i-1](tempf)\n",
        "            tempf = self.ReLU2[2*i](tempf)\n",
        "            tempf = self.bn2[2*i](tempf)\n",
        "            tempf = self.conv2[4*i](tempf)\n",
        "            tempf = self.conv2[4*i+1](tempf)\n",
        "            tempf = self.ReLU2[2*i+1](tempf)\n",
        "            tempf = self.bn2[2*i+1](tempf)            \n",
        "            self.feature2.append(tempf)\n",
        "        tempf = self.uconv2[config.MaxLv-2](self.feature2[-1])\n",
        "        tempf = torch.cat((self.feature2[1],tempf),dim=1)\n",
        "        tempf = self.conv2[-2](tempf)\n",
        "        tempf = self.ReLU2[4*config.MaxLv-4](tempf)\n",
        "        tempf = self.bn2[4*config.MaxLv-4](tempf)\n",
        "        tempf = self.conv2[-1](tempf)\n",
        "        tempf = self.ReLU2[4*config.MaxLv-3](tempf)\n",
        "        tempf = self.bn2[4*config.MaxLv-3](tempf)            \n",
        "        self.feature2.append(tempf)\n",
        "        tempf = self.reconsconv(self.feature2[-1])\n",
        "        tempf = self.ReLU2[-1](tempf)\n",
        "        self.feature2[-1] = self.bn2[-1](tempf)\n",
        "        '''\n",
        "\n",
        "\n",
        "\n",
        "config = Config()\n",
        "def add_conv_stage(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=True, useBN=False):\n",
        "  if useBN:\n",
        "    return nn.Sequential(\n",
        "      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
        "      nn.BatchNorm2d(dim_out),\n",
        "      nn.LeakyReLU(0.1),\n",
        "      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
        "      nn.BatchNorm2d(dim_out),\n",
        "      nn.LeakyReLU(0.1)\n",
        "    )\n",
        "  else:\n",
        "    return nn.Sequential(\n",
        "      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
        "      nn.ReLU()\n",
        "    )\n",
        "\n",
        "def add_merge_stage(ch_coarse, ch_fine, in_coarse, in_fine, upsample):\n",
        "  conv = nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n",
        "  torch.cat(conv, in_fine)\n",
        "\n",
        "  return nn.Sequential(\n",
        "    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n",
        "  )\n",
        "  upsample(in_coarse)\n",
        "\n",
        "def upsample(ch_coarse, ch_fine):\n",
        "  return nn.Sequential(\n",
        "    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False),\n",
        "    nn.ReLU()\n",
        "  )\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, useBN=False):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.conv1   = add_conv_stage(config.InputCh, 32, useBN=useBN)\n",
        "    self.conv2   = add_conv_stage(32, 64, useBN=useBN)\n",
        "    self.conv3   = add_conv_stage(64, 128, useBN=useBN)\n",
        "    self.conv4   = add_conv_stage(128, 256, useBN=useBN)\n",
        "    self.conv5   = add_conv_stage(256, 512, useBN=useBN)\n",
        "\n",
        "    self.conv4m = add_conv_stage(512, 256, useBN=useBN)\n",
        "    self.conv3m = add_conv_stage(256, 128, useBN=useBN)\n",
        "    self.conv2m = add_conv_stage(128,  64, useBN=useBN)\n",
        "    self.conv1m = add_conv_stage( 64,  32, useBN=useBN)\n",
        "\n",
        "    self.conv0  = nn.Sequential(\n",
        "        nn.Conv2d(32, config.K, 3, 1, 1),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Softmax2d()\n",
        "    )\n",
        "    self.pad = nn.ConstantPad2d(config.radius-1,0)\n",
        "    self.max_pool = nn.MaxPool2d(2)\n",
        "\n",
        "    self.upsample54 = upsample(512, 256)\n",
        "    self.upsample43 = upsample(256, 128)\n",
        "    self.upsample32 = upsample(128,  64)\n",
        "    self.upsample21 = upsample(64 ,  32)\n",
        "    ## weight initialization\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        if m.bias is not None:\n",
        "          m.bias.data.zero_()\n",
        "    #self.Kconst = torch.tensor(config.K).float()\n",
        "    #self.cropped_seg = torch.zeros(config.BatchSize,config.K,config.inputsize[0],config.inputsize[1],(config.radius-1)*2+1,(config.radius-1)*2+1)\n",
        "    #self.loss = NCutsLoss()\n",
        "\n",
        "\n",
        "  def forward(self, x):#, weight):\n",
        "    #sw = weight.sum(-1).sum(-1)\n",
        "    conv1_out = self.conv1(x)\n",
        "    #return self.upsample21(conv1_out)\n",
        "    conv2_out = self.conv2(self.max_pool(conv1_out))\n",
        "    conv3_out = self.conv3(self.max_pool(conv2_out))\n",
        "    conv4_out = self.conv4(self.max_pool(conv3_out))\n",
        "    conv5_out = self.conv5(self.max_pool(conv4_out))\n",
        "\n",
        "    conv5m_out = torch.cat((self.upsample54(conv5_out), conv4_out), 1)\n",
        "    conv4m_out = self.conv4m(conv5m_out)\n",
        "\n",
        "    conv4m_out_ = torch.cat((self.upsample43(conv4m_out), conv3_out), 1)\n",
        "    conv3m_out = self.conv3m(conv4m_out_)\n",
        "\n",
        "    conv3m_out_ = torch.cat((self.upsample32(conv3m_out), conv2_out), 1)\n",
        "    conv2m_out = self.conv2m(conv3m_out_)\n",
        "\n",
        "    conv2m_out_ = torch.cat((self.upsample21(conv2m_out), conv1_out), 1)\n",
        "    conv1m_out = self.conv1m(conv2m_out_)\n",
        "\n",
        "    conv0_out = self.conv0(conv1m_out)\n",
        "    padded_seg = self.pad(conv0_out)\n",
        "    '''for m in torch.arange((config.radius-1)*2+1,dtype=torch.long):\n",
        "        for n in torch.arange((config.radius-1)*2+1,dtype=torch.long):\n",
        "            self.cropped_seg[:,:,:,:,m,n]=padded_seg[:,:,m:m+conv0_out.size()[2],n:n+conv0_out.size()[3]].clone()\n",
        "    multi1 = self.cropped_seg.mul(weight)\n",
        "    multi2 = multi1.view(multi1.shape[0],multi1.shape[1],multi1.shape[2],multi1.shape[3],-1).sum(-1).mul(conv0_out)\n",
        "    multi3 = sum_weight.mul(conv0_out)\n",
        "    assocA = multi2.view(multi2.shape[0],multi2.shape[1],-1).sum(-1)\n",
        "    assocV = multi3.view(multi3.shape[0],multi3.shape[1],-1).sum(-1)\n",
        "    assoc = assocA.div(assocV).sum(-1)\n",
        "    loss = self.Kconst - assoc'''\n",
        "    #loss = self.loss(conv0_out, padded_seg, weight, sw)\n",
        "    return [conv0_out,padded_seg]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpewACKC-neT"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "from torch.autograd import Function\n",
        "import time\n",
        "import pdb\n",
        "import subprocess\n",
        "import numpy as np\n",
        "\n",
        "config = Config()\n",
        "\n",
        "class NCutsLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NCutsLoss,self).__init__()\n",
        "        self.gpu_list = []\n",
        "        '''\n",
        "        for i in range(torch.cuda.device_count()):\n",
        "            self.gpu_list.append(torch.cuda.device(i))\n",
        "# the ratio of the free space among all gpus\n",
        "        self.gpu_room_list = []\n",
        "        self.gpu_room_update()\n",
        "        '''\n",
        "    '''def gpu_room_update(self):\n",
        "        self.gpu_room_list = []\n",
        "        free_memory = get_gpu_memory_map()\n",
        "        total_free = 0\n",
        "        count_ratio = 0.0\n",
        "        for _, value in free_memory.items():\n",
        "            total_free+=value\n",
        "        for dev in self.gpu_list:\n",
        "            ratio = float(free_memory[dev])/total_free\n",
        "            self.gpu_room_list.append(ratio)\n",
        "            count_ratio += ratio\n",
        "        if (count_ratio - 1 < 0):\n",
        "            self.gpu_room_list[-1]+=1.0-count_ratio \n",
        "    '''    \n",
        "            \n",
        "\n",
        "    def forward(self, seg, padded_seg, weight,sum_weight):\n",
        "        #too many values to unpack\n",
        "        cropped_seg = []\n",
        "        for m in torch.arange((config.radius-1)*2+1,dtype=torch.long):\n",
        "            column = []\n",
        "            for n in torch.arange((config.radius-1)*2+1,dtype=torch.long):\n",
        "                column.append(padded_seg[:,:,m:m+seg.size()[2],n:n+seg.size()[3]].clone())\n",
        "            cropped_seg.append(torch.stack(column,4))\n",
        "        cropped_seg = torch.stack(cropped_seg,4)\n",
        "        #for m in torch.arange(50,70,dtype=torch.long):\n",
        "\n",
        "        #    print(m)\n",
        "        #    for n in torch.arange(50,70,dtype= torch.long):\n",
        "        #        print(weight[5,0,m,n])\n",
        "        multi1 = cropped_seg.mul(weight)\n",
        "        multi2 = multi1.sum(-1).sum(-1).mul(seg)\n",
        "        multi3 = sum_weight.mul(seg)\n",
        "        #print(\"=============================================================================\")\n",
        "        #for a in [0,1]:\n",
        "        #    print(multi2[5,0,a*10+50:a*10+60,50:60])\n",
        "        #    print(multi2[5,0,a*10+50:a*10+60,60:70])\n",
        "        assocA = multi2.view(multi2.shape[0],multi2.shape[1],-1).sum(-1)\n",
        "        assocV = multi3.view(multi3.shape[0],multi3.shape[1],-1).sum(-1)\n",
        "        assoc = assocA.div(assocV).sum(-1)\n",
        "        \n",
        "        return torch.add(-assoc,config.K)\n",
        "        \n",
        "    '''def crop_seg(self,seg):\n",
        "        cropped_seg = torch.zeros(seg.size()[0],seg.size()[1],seg.size()[2],seg.size()[3],(config.radius-1)*2+1,(config.radius-1)*2+1)\n",
        "        padding_size = (config.radius,config.radius,config.radius,config.radius)\n",
        "        padded_seg = torch.nn.functional.pad(seg,padding_size)\n",
        "        for m in torch.arange((config.radius-1)*2+1,dtype=torch.long):\n",
        "            for n in torch.arange((config.radius-1)*2+1,dtype=torch.long):\n",
        "                cropped_seg[:,:,:,:,m,n].copy_(padded_seg[:,:,m:m+seg.size()[2],n:n+seg.size()[3]])\n",
        "        return cropped_seg\n",
        "    \n",
        "def get_gpu_memory_map():\n",
        "    \"\"\"Get the current gpu usage.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    usage: dict\n",
        "        Keys are device ids as integers.\n",
        "        Values are memory free as integers in MB.\n",
        "    \"\"\"\n",
        "    result = subprocess.check_output(\n",
        "        [\n",
        "            'nvidia-smi', '--query-gpu=memory.free',\n",
        "            '--format=csv,nounits,noheader'\n",
        "        ], encoding='utf-8')\n",
        "    # Convert lines into a dictionary\n",
        "    gpu_memory = [int(x) for x in result.strip().split('\\n')]\n",
        "    gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n",
        "    return gpu_memory_map\n",
        "'''        \n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2pF-Xxa-z6n",
        "outputId": "23ec493d-e57c-49d9-878e-af154da793b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "config = Config()\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=config.cuda_dev_list\n",
        "if __name__ == '__main__':\n",
        "    dataset = DataLoader(config.pascal,\"train\")\n",
        "    dataloader = dataset.torch_loader()\n",
        "    #model = torch.nn.DataParallel(Net(True))\n",
        "    model = torch.nn.DataParallel(WNet())\n",
        "    model.cuda()\n",
        "    #model.to(device)\n",
        "    model.train()\n",
        "    #optimizer\n",
        "    \n",
        "    optimizer = torch.optim.SGD(model.parameters(),lr = config.init_lr)\n",
        "    #reconstr = torch.nn.MSELoss().cuda(config.cuda_dev)\n",
        "    Ncuts = NCutsLoss()\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config.lr_decay_iter, gamma=config.lr_decay)\n",
        "    \n",
        "    for epoch in range(config.max_iter):\n",
        "        print(\"Epoch: \"+str(epoch+1))\n",
        "        scheduler.step()\n",
        "        Ave_Ncuts = 0.0\n",
        "        #Ave_Rec = 0.0\n",
        "        t_load = 0.0\n",
        "        t_forward = 0.0\n",
        "        t_loss = 0.0\n",
        "        t_backward = 0.0\n",
        "        t_adjust = 0.0\n",
        "        t_reset = 0.0\n",
        "        t_inloss = 0.0\n",
        "        for step,[x,w] in enumerate(dataloader):\n",
        "            #NCuts Loss\n",
        "            #tick = time.time()\n",
        "            x = x.cuda()\n",
        "            w = w.cuda()\n",
        "            #for m in torch.arange(50,70,dtype=torch.long):\n",
        "\n",
        "            #    print(m)\n",
        "            #    for n in torch.arange(50,70,dtype= torch.long):\n",
        "            #        print(w[5,0,m,n])\n",
        "            sw = w.sum(-1).sum(-1)\n",
        "            #t_load += time.time()-tick\n",
        "            #tick = time.time()\n",
        "            optimizer.zero_grad()\n",
        "            pred,pad_pred = model(x)\n",
        "            #t_forward += time.time()-tick\n",
        "            #pred.cuda()\n",
        "            #tick = time.time()\n",
        "            ncuts_loss = Ncuts(pred,pad_pred,w,sw)\n",
        "            ncuts_loss = ncuts_loss.sum()/config.BatchSize \n",
        "            #t_loss += time.time()-tick\n",
        "            #tick = time.time()\n",
        "            Ave_Ncuts = (Ave_Ncuts * step + ncuts_loss.item())/(step+1)\n",
        "            #t_reset += time.time()-tick\n",
        "            #tick = time.time()\n",
        "            ncuts_loss.backward()\n",
        "            #t_backward += time.time()-tick\n",
        "            #tick = time.time()\n",
        "            optimizer.step()\n",
        "            #t_adjust += time.time()-tick\n",
        "            #Reconstruction Loss\n",
        "            '''pred,rec_image = model(x)\n",
        "            rec_loss = reconstr(rec_image,x)\n",
        "            Ave_Rec = (Ave_Rec * step + rec_loss.item())/(step+1)\n",
        "            optimizer.zero_grad()\n",
        "            rec_loss.backward()\n",
        "            optimizer.step()'''\n",
        "        #t_total = t_load+t_reset+t_forward+t_loss+t_backward+t_adjust\n",
        "        print(\"Ncuts loss: \"+str(Ave_Ncuts))#+\";total time: \"+str(t_total)+\";forward: \"+str(t_forward/t_total)+\";loss: \"+str(t_loss/t_total)+\";backward: \"+str(t_backward/t_total)+\";adjust: \"+str(t_adjust/t_total)+\";reset&load: \"+str(t_reset/t_total)+\"&\"+str(t_load/t_total)+\"loss: \"+str(t_loss)+\" / \"+str(t_inloss))\n",
        "        #print(\"Reconstruction loss: \"+str(Ave_Rec))\n",
        "        if (epoch+1)%500 == 0:\n",
        "            localtime = time.localtime(time.time())\n",
        "            checkname = './checkpoints'\n",
        "            if not os.path.isdir(checkname):\n",
        "                os.mkdir(checkname)\n",
        "            checkname+='/checkpoint'\n",
        "            for i in range(1,5):\n",
        "                checkname+='_'+str(localtime[i])\n",
        "            checkname += '_epoch_'+str(epoch+1)\n",
        "            with open(checkname,'wb') as f:\n",
        "                torch.save({\n",
        "                    'epoch': epoch +1,\n",
        "                    'state_dict': model.module.state_dict(),\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                    'scheduler': scheduler.state_dict(),\n",
        "                    'Ncuts': Ave_Ncuts#,\n",
        "                    #'recon': Ave_Rec\n",
        "                    },f)\n",
        "            print(checkname+' saved')\n",
        "    "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['6.png', '4.png', '2.png', '10.png', '5.png', '9.png', '3.png', '7.png', '11.png', '8.png', '0.png', '1.png', '15.png', '21.png', '24.png', '18.png', '23.png', '25.png', '14.png', '17.png', '26.png', '20.png', '13.png', '27.png', '19.png', '16.png', '22.png', '12.png', '43.png', '30.png', '29.png', '32.png', '35.png', '40.png', '44.png', '37.png', '38.png', '33.png', '28.png', '36.png', '42.png', '45.png', '31.png', '41.png', '39.png', '34.png', '53.png', '63.png', '59.png', '50.png', '62.png', '51.png', '54.png', '58.png', '46.png', '61.png', '49.png', '56.png', '48.png', '60.png', '55.png', '57.png', '52.png', '47.png', '64.png', '78.png', '76.png', '66.png', '67.png', '79.png', '74.png', '75.png', '80.png', '72.png', '73.png', '65.png', '77.png', '69.png', '68.png', '70.png', '71.png', '93.png', '94.png', '90.png', '92.png', '89.png', '82.png', '88.png', '85.png', '86.png', '84.png', '95.png', '87.png', '97.png', '81.png', '83.png', '96.png', '91.png', '111.png', '107.png', '98.png', '104.png', '108.png', '109.png', '99.png', '103.png', '105.png', '115.png', '101.png', '113.png', '100.png', '110.png', '114.png', '106.png', '112.png', '102.png', '116.png', '127.png', '128.png', '122.png', '129.png', '123.png', '131.png', '120.png', '121.png', '132.png', '118.png', '124.png', '130.png', '117.png', '133.png', '119.png', '125.png', '126.png', '144.png', '146.png', '147.png', '141.png', '138.png', '136.png', '134.png', '137.png', '139.png', '142.png', '140.png', '148.png', '135.png', '145.png', '143.png']\n",
            "0\n",
            "calculating weights.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-2512db6c321c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda_dev_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpascal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#model = torch.nn.DataParallel(Net(True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-43ddf37c38ce>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, datapath, mode)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m#calculate weights by 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-43ddf37c38ce>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self, raw_data, shape, batch_size)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0mtmp_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-43ddf37c38ce>\u001b[0m in \u001b[0;36mcal_weight\u001b[0;34m(self, raw_data, shape)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"calculating weights.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mdissim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mpadded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/cupy/creation/basic.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, order)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \"\"\"\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemset_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.ndarray.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.alloc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._malloc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory._try_malloc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: Out of memory allocating 4,425,523,200 bytes (allocated so far: 0 bytes)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3LCuylVEXsv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}